{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Basic Datacleaning and data exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "#import dask.dataframe as dd\n",
    "#from dask.diagnostics import ProgressBar \n",
    "#import hvplot.dask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Current working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../../dataset\")\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#os.chdir(\"../dataset\")\n",
    "columns = ['PDG ID','Px','Py','Pz' ,'E','m','Status']\n",
    "df = pd.read_parquet('myfile3.parquet', engine=\"pyarrow\", columns=columns)\n",
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parsing columns names>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'PDG ID': 'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# printing summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "from pyarrow.parquet import ParquetDataset\n",
    "\n",
    "dataset = ParquetDataset(\"myfile2.parquet\")\n",
    "table = dataset.read()\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datacleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "print('Missing values per column :')\n",
    "print(missing_values_count[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecting the repeating values in ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ID has no unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['ID', 'Px', 'Py','Pz','E','m']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting ID =22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### checking for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22 = df[df.ID==22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###checking ratio of duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate = df_22.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The ratio of duplicate rows are :')\n",
    "# print((duplicate.sum()/df_22.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_22.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_22.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_22[duplicate].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22[df_22.duplicated()] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22[df_22[['ID', 'Px', 'Py','Pz','E','m']].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22[['ID', 'Px', 'Py','Pz','E','m']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22.loc[df_22.duplicated(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22_small = df_22.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b =df_22_small.drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing test dataframe and checking for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'Name': ['Tom','Tom','Tom','Tom' ,'Joseph', 'Krish', 'John'], 'Age': [20,20,20,20, 21, 19, 18]}  \n",
    "  \n",
    "# # Create DataFrame  \n",
    "# test_df = pd.DataFrame(data)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df\n",
    "# #removing duplicates and keeping just the last\n",
    "# testdf_noduplicate =df.drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf_noduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x =['total_length','length with duplicates removed']\n",
    "# y =[len(df),len(testdf_noduplicate)]\n",
    "# plt.bar(x,y)\n",
    "# plt.title('testdf vs testdf_without duplicates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in data with duplicates removed and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID','Px','Py','Pz' ,'E','m','Status']\n",
    "df_noduplicate = pd.read_parquet('myfile4.parquet', engine=\"pyarrow\", columns=columns)\n",
    "print(df_noduplicate.info())\n",
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =['total_length of real data','length with duplicates removed']\n",
    "y =[len(df),len(df_noduplicate)]\n",
    "# plt.bar(x,y)\n",
    "# plt.title('dataframe vs dataframe_without duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('darkgrid')\n",
    "# sns.barplot(x, y)\n",
    "# plt.title('dataframe vs dataframe_without duplicates')\n",
    "# plt.show()\n",
    "# print('Total data length:{2.2} ',x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ind = np.arange(len(y)\n",
    "# ax.barh(ind, y,color =['b','r'])\n",
    "# ax.set_yticks(ind)\n",
    "# ax.set_yticklabels(x)\n",
    "\n",
    "# # new helper method to auto-label bars\n",
    "# ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(len(y))\n",
    "colors = ['b','r']\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.35\n",
    "ax.barh(ind, y,width,color = colors)\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(x)\n",
    "\n",
    "# new helper method to auto-label bars\n",
    "ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the stratified sampled with respect to Energy for graphic analysis as a new parquet file named as smallforgraphs. parquet for analysis in local machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##not necessary to run ,already got the file\n",
    "# df3 = df_noduplicate.groupby('E', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "# df3.to_parquet('smallforgraphs.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading smaller dataset to do visual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('smallforgraphs.parquet', engine=\"pyarrow\")\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## scaling and normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "scaled_data = minmax_scaling(df, columns=['Px', 'Py','Pz','E','m'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Px','Py','Pz' ,'E','m']\n",
    "np.random.seed(0)\n",
    "normalized_data = normalize(df).drop(['ID','Status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##random sampling 10% of df, normalized_df and scaled_df for visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "norm1 = normalized_data.sample(frac =0.1)\n",
    "scale1 = scaled_data.sample(frac = 0.1)\n",
    "df1 = df.sample(frac = 0.1).drop(['ID','Status'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data ,normalized data and scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(df1, \n",
    "                   title='\"Original Data\"',\n",
    "                   opacity=0.8,\n",
    "                   log_y=True# represent bars with log scale\n",
    "                    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df1, x=\"E\", points = 'all')\n",
    "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = []\n",
    "#group_labels = []\n",
    "#group_labels = ['Group 1', 'Group 2', 'Group 3']\n",
    "colors = ['#333F44', '#37AA9C', '#94F3E4']\n",
    "for feature in df1.columns:\n",
    "    hist_data = [df[feature]\n",
    "    fig = ff.create_distplot(hist_data, feature, show_hist=False, colors='#333F44')\n",
    "\n",
    "# Add title\n",
    "    fig.update_layout(title_text= feature + ' Distribution')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df1.columns:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in df1.columns:\n",
    "    plt.figure()             # <==================== here!\n",
    "    sns.distplot(df1[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in norm1.columns:\n",
    "    plt.figure()             # <==================== here!\n",
    "    sns.distplot(norm1[column],color=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in scale1.columns:\n",
    "    plt.figure()             # <==================== here!\n",
    "    sns.distplot(scale1[column],color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}